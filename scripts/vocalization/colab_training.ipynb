{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSN 2.0 - Vocalization Classifier Training (Colab GPU)\n",
    "\n",
    "Train alle 232 Nederlandse vogelsoorten met GPU acceleratie.\n",
    "\n",
    "**Geschatte tijd:** 1-2 dagen (vs 9 maanden op NAS CPU)\n",
    "\n",
    "## Setup\n",
    "1. Upload je spectrogrammen naar Google Drive\n",
    "2. Vul je database credentials in\n",
    "3. Run alle cellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install psycopg2-binary librosa scikit-learn matplotlib seaborn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Maak werkdirectories\n",
    "import os\n",
    "DRIVE_BASE = '/content/drive/MyDrive/EMSN-Vocalization'\n",
    "os.makedirs(f'{DRIVE_BASE}/models', exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_BASE}/logs', exist_ok=True)\n",
    "print(f\"Werkdirectory: {DRIVE_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATIE ===\n",
    "# Vul hier je database credentials in\n",
    "# (of upload een .env bestand naar Drive)\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': 'JOUW_PUBLIEKE_IP',  # Je router's publieke IP of een tunnel\n",
    "    'port': 5433,\n",
    "    'database': 'emsn',\n",
    "    'user': 'birdpi_zolder',\n",
    "    'password': 'JOUW_WACHTWOORD'\n",
    "}\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32  # Groter mogelijk met GPU\n",
    "LEARNING_RATE = 0.001\n",
    "VERSION = '2025'  # Jaarversie i.p.v. kwartaal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connectie test\n",
    "import psycopg2\n",
    "\n",
    "def get_db():\n",
    "    return psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "try:\n",
    "    conn = get_db()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT COUNT(*) FROM vocalization_training\")\n",
    "    count = cur.fetchone()[0]\n",
    "    print(f\"✅ Database verbonden! {count} soorten in training tabel.\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Database error: {e}\")\n",
    "    print(\"\\nTips:\")\n",
    "    print(\"1. Zet port forwarding aan op je router (5433 -> NAS)\")\n",
    "    print(\"2. Of gebruik ngrok/cloudflare tunnel\")\n",
    "    print(\"3. Check of PostgreSQL externe connecties accepteert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model (zelfde architectuur als NAS versie)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class VocalizationCNN(nn.Module):\n",
    "    \"\"\"CNN voor vocalisatie classificatie (song/call/alarm).\"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(128, 128), num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Conv block 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Conv block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Conv block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # Bereken flatten size\n",
    "        h, w = input_shape[0] // 8, input_shape[1] // 8\n",
    "        flatten_size = 128 * h * w\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flatten_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Test model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VocalizationCNN().to(device)\n",
    "print(f\"Model op: {device}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogrammen laden vanuit Drive\n",
    "# Je moet eerst je spectrogrammen uploaden naar Drive!\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "SPECTROGRAMS_DIR = Path(f'{DRIVE_BASE}/spectrograms')\n",
    "\n",
    "def load_spectrograms_for_species(species_dir):\n",
    "    \"\"\"Laad spectrogrammen voor een soort.\"\"\"\n",
    "    X, y = [], []\n",
    "    label_map = {'song': 0, 'call': 1, 'alarm': 2}\n",
    "    \n",
    "    for label_name, label_idx in label_map.items():\n",
    "        label_dir = species_dir / label_name\n",
    "        if not label_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        for npy_file in label_dir.glob('*.npy'):\n",
    "            try:\n",
    "                spec = np.load(npy_file)\n",
    "                # Resize naar 128x128 als nodig\n",
    "                if spec.shape != (128, 128):\n",
    "                    from skimage.transform import resize\n",
    "                    spec = resize(spec, (128, 128), anti_aliasing=True)\n",
    "                X.append(spec)\n",
    "                y.append(label_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"  Skip {npy_file}: {e}\")\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Check welke soorten beschikbaar zijn\n",
    "if SPECTROGRAMS_DIR.exists():\n",
    "    species_dirs = [d for d in SPECTROGRAMS_DIR.iterdir() if d.is_dir()]\n",
    "    print(f\"Gevonden: {len(species_dirs)} soorten in Drive\")\n",
    "else:\n",
    "    print(f\"❌ Directory niet gevonden: {SPECTROGRAMS_DIR}\")\n",
    "    print(\"\\nUpload je spectrogrammen naar Google Drive:\")\n",
    "    print(f\"  {DRIVE_BASE}/spectrograms/<soort>/song/*.npy\")\n",
    "    print(f\"  {DRIVE_BASE}/spectrograms/<soort>/call/*.npy\")\n",
    "    print(f\"  {DRIVE_BASE}/spectrograms/<soort>/alarm/*.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functie\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "def train_species(species_name, species_dir, version=VERSION):\n",
    "    \"\"\"Train model voor één soort.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training: {species_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Laad data\n",
    "    X, y = load_spectrograms_for_species(species_dir)\n",
    "    \n",
    "    if len(X) < 100:\n",
    "        print(f\"  ⚠️ Te weinig data: {len(X)} spectrogrammen (min 100)\")\n",
    "        return None, 'insufficient_data'\n",
    "    \n",
    "    print(f\"  Data: {len(X)} spectrogrammen\")\n",
    "    \n",
    "    # Check class balance\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    if len(unique) < 2:\n",
    "        print(f\"  ⚠️ Maar {len(unique)} klasse(s), minimaal 2 nodig\")\n",
    "        return None, 'insufficient_classes'\n",
    "    \n",
    "    print(f\"  Klassen: {dict(zip(['song', 'call', 'alarm'], counts))}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Naar tensors\n",
    "    X_train = torch.FloatTensor(X_train).unsqueeze(1)  # Add channel dim\n",
    "    X_val = torch.FloatTensor(X_val).unsqueeze(1)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_val = torch.LongTensor(y_val)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train, y_train),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        TensorDataset(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = VocalizationCNN(num_classes=len(unique)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    best_acc = 0\n",
    "    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "                val_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "        \n",
    "        # Metrics\n",
    "        train_acc = train_correct / len(X_train)\n",
    "        val_acc = val_correct / len(X_val)\n",
    "        \n",
    "        history['loss'].append(train_loss / len(train_loader))\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{EPOCHS} - val_acc: {val_acc:.1%}\")\n",
    "    \n",
    "    # Save model\n",
    "    dirname = species_dir.name\n",
    "    model_filename = f\"{dirname}_cnn_{version}.pt\"\n",
    "    model_path = Path(f'{DRIVE_BASE}/models/{model_filename}')\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'num_classes': len(unique),\n",
    "        'accuracy': best_acc,\n",
    "        'history': history,\n",
    "        'species_name': species_name,\n",
    "        'version': version\n",
    "    }, model_path)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  ✅ Klaar! Accuracy: {best_acc:.1%}, Tijd: {elapsed/60:.1f} min\")\n",
    "    print(f\"  Model: {model_path}\")\n",
    "    \n",
    "    return best_acc, 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train alle soorten\n",
    "from datetime import datetime\n",
    "\n",
    "results = []\n",
    "start_all = time.time()\n",
    "\n",
    "print(f\"Start training: {datetime.now()}\")\n",
    "print(f\"Soorten: {len(species_dirs)}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print()\n",
    "\n",
    "for i, species_dir in enumerate(sorted(species_dirs)):\n",
    "    species_name = species_dir.name.replace('_', ' ').title()\n",
    "    print(f\"[{i+1}/{len(species_dirs)}] \", end='')\n",
    "    \n",
    "    try:\n",
    "        acc, status = train_species(species_name, species_dir)\n",
    "        results.append({\n",
    "            'species': species_name,\n",
    "            'accuracy': acc,\n",
    "            'status': status\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        results.append({\n",
    "            'species': species_name,\n",
    "            'accuracy': None,\n",
    "            'status': f'error: {str(e)[:50]}'\n",
    "        })\n",
    "\n",
    "elapsed_all = time.time() - start_all\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Totale tijd: {elapsed_all/3600:.1f} uur\")\n",
    "print(f\"Succesvol: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"Mislukt: {sum(1 for r in results if r['status'] != 'success')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultaten opslaan\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Als DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'{DRIVE_BASE}/training_results_{VERSION}.csv', index=False)\n",
    "\n",
    "# Samenvatting\n",
    "successful = df[df['status'] == 'success']\n",
    "print(f\"\\nSamenvatting:\")\n",
    "print(f\"  Getraind: {len(successful)} soorten\")\n",
    "print(f\"  Gem. accuracy: {successful['accuracy'].mean():.1%}\")\n",
    "print(f\"  Min accuracy: {successful['accuracy'].min():.1%}\")\n",
    "print(f\"  Max accuracy: {successful['accuracy'].max():.1%}\")\n",
    "\n",
    "# Top 10\n",
    "print(f\"\\nTop 10 beste modellen:\")\n",
    "print(successful.nlargest(10, 'accuracy')[['species', 'accuracy']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update database met resultaten (optioneel)\n",
    "# Dit werkt alleen als je database extern bereikbaar is\n",
    "\n",
    "def update_database_with_results(results):\n",
    "    \"\"\"Update vocalization_model_versions tabel.\"\"\"\n",
    "    try:\n",
    "        conn = get_db()\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        for r in results:\n",
    "            if r['status'] != 'success':\n",
    "                continue\n",
    "            \n",
    "            dirname = r['species'].lower().replace(' ', '_')\n",
    "            model_file = f\"{dirname}_cnn_{VERSION}.pt\"\n",
    "            \n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO vocalization_model_versions \n",
    "                (species_name, version, model_file, accuracy, is_active, notes)\n",
    "                VALUES (%s, %s, %s, %s, TRUE, 'Trained on Colab GPU')\n",
    "                ON CONFLICT (species_name, version) \n",
    "                DO UPDATE SET accuracy = EXCLUDED.accuracy, \n",
    "                              model_file = EXCLUDED.model_file,\n",
    "                              trained_at = NOW()\n",
    "            \"\"\", (r['species'], VERSION, model_file, r['accuracy']))\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"✅ Database bijgewerkt met {len([r for r in results if r['status'] == 'success'])} modellen\")\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Database update mislukt: {e}\")\n",
    "        print(\"Je kunt de modellen handmatig kopiëren naar de NAS\")\n",
    "\n",
    "# Uncomment om database te updaten:\n",
    "# update_database_with_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na de training\n",
    "\n",
    "De getrainde modellen staan nu in Google Drive:\n",
    "- `EMSN-Vocalization/models/*.pt`\n",
    "\n",
    "Om ze te gebruiken op je NAS:\n",
    "\n",
    "1. Download de `models/` map van Drive\n",
    "2. Kopieer naar `/volume1/docker/emsn-vocalization/data/models/`\n",
    "3. De modellen worden automatisch herkend"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
