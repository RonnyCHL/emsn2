{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# EMSN 2.0 - Vocalization Classifier Training Batch 2\n## Geoptimaliseerd voor Colab Pro (A100/V100)\n\nTrain de **61 ontbrekende soorten** met maximale GPU acceleratie.\n\n### Optimalisaties:\n- **Parallel downloads** - 8 gelijktijdige audio downloads\n- **Grote batch size** - 128 (A100) of 64 (V100/T4)\n- **Mixed Precision (FP16)** - 2x snellere training op A100\n- **Multi-worker DataLoader** - CPU preprocessing parallel aan GPU\n- **Async spectrogram generatie** - ThreadPool voor I/O\n\n**Geschatte tijd:** \n- A100: ~20-30 minuten\n- V100: ~45-60 minuten  \n- T4: ~90 minuten"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU en bepaal optimale instellingen\n!nvidia-smi\n\nimport torch\nimport gc\n\n# Clean GPU memory\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"GPU: {gpu_name}\")\n    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n    \n    # === STABILITY SETTINGS ===\n    torch.backends.cuda.matmul.allow_tf32 = False\n    torch.backends.cudnn.allow_tf32 = False\n    torch.backends.cudnn.benchmark = False  # Meer stabiel\n    torch.backends.cudnn.deterministic = True\n    print(\"‚úÖ CUDA stability settings toegepast\")\n    \n    # Configuratie - conservatief voor stabiliteit\n    if 'A100' in gpu_name:\n        GPU_TYPE = 'A100'\n        RECOMMENDED_BATCH = 32  # Klein voor stabiliteit\n        print(f\"\\nüöÄ A100 gedetecteerd - Stability mode\")\n    elif 'V100' in gpu_name:\n        GPU_TYPE = 'V100'\n        RECOMMENDED_BATCH = 32\n    elif 'L4' in gpu_name:\n        GPU_TYPE = 'L4'\n        RECOMMENDED_BATCH = 32\n    else:\n        GPU_TYPE = 'T4'\n        RECOMMENDED_BATCH = 32\n        print(f\"\\n‚úÖ T4 gedetecteerd\")\n    \n    # MIXED PRECISION UITGESCHAKELD - voorkomt CUDA errors\n    USE_AMP = False\n    print(\"‚ö†Ô∏è Mixed Precision UITGESCHAKELD voor stabiliteit\")\n    \nelse:\n    GPU_TYPE = 'CPU'\n    RECOMMENDED_BATCH = 16\n    USE_AMP = False\n    print(\"‚ö†Ô∏è Geen GPU!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (inclusief async/parallel libraries)\n!pip install librosa scikit-learn scikit-image matplotlib tqdm requests aiohttp aiofiles -q\nprint(\"‚úÖ Dependencies ge√Ønstalleerd\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Lokale opslag (geen Google Drive nodig)\nimport os\n\n# Gebruik Colab lokale storage - geen Drive mount nodig\nDRIVE_BASE = '/content/EMSN-Vocalization'\nMODELS_DIR = f'{DRIVE_BASE}/models'\nAUDIO_DIR = f'{DRIVE_BASE}/audio'\n\nos.makedirs(MODELS_DIR, exist_ok=True)\nos.makedirs(AUDIO_DIR, exist_ok=True)\n\nprint(f\"‚úÖ Lokale opslag geconfigureerd:\")\nprint(f\"   Models: {MODELS_DIR}\")\nprint(f\"   Audio: {AUDIO_DIR}\")\nprint(f\"\\n‚ö†Ô∏è Let op: Data verdwijnt na sessie!\")\nprint(f\"   Download modellen aan het eind via cel 12\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === CONFIGURATIE (Auto-optimized voor jouw GPU) ===\nVERSION = '2025'\nEPOCHS = 25\nLEARNING_RATE = 0.001\nMIN_SAMPLES = 50\n\n# Automatisch geoptimaliseerde batch size\nBATCH_SIZE = RECOMMENDED_BATCH\nNUM_WORKERS = 4 if GPU_TYPE in ['A100', 'V100', 'L4'] else 2\n\n# Parallel download instellingen\nMAX_CONCURRENT_DOWNLOADS = 8 if GPU_TYPE in ['A100', 'V100'] else 4\nMAX_RECORDINGS_PER_TYPE = 25  # Meer data voor betere modellen\n\nprint(f\"üìä Configuratie voor {GPU_TYPE}:\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   DataLoader workers: {NUM_WORKERS}\")\nprint(f\"   Parallel downloads: {MAX_CONCURRENT_DOWNLOADS}\")\nprint(f\"   Mixed Precision: {USE_AMP}\")\nprint(f\"   Epochs: {EPOCHS}\")\n\n# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n# ‚ïë  Xeno-canto API key                                            ‚ïë\n# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\nXC_API_KEY = '14258afd1c8a8e055387d012f2620e20f59ef3a2'\n\nif not XC_API_KEY:\n    print(\"\\n‚ö†Ô∏è  WAARSCHUWING: Geen API key ingevuld!\")\n    print(\"   Vul je key in en run deze cel opnieuw.\")\nelse:\n    print(f\"\\n‚úÖ API key geconfigureerd ({len(XC_API_KEY)} karakters)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontbrekende soorten voor batch 2\n",
    "# Format: (Nederlandse naam, Wetenschappelijke naam, directory_naam)\n",
    "\n",
    "MISSING_SPECIES = [\n",
    "    # Prioriteit 1 - ZEER BELANGRIJK\n",
    "    (\"Kauw\", \"Coloeus monedula\", \"kauw\"),\n",
    "    (\"Kokmeeuw\", \"Chroicocephalus ridibundus\", \"kokmeeuw\"),\n",
    "    (\"Nijlgans\", \"Alopochen aegyptiaca\", \"nijlgans\"),\n",
    "    \n",
    "    # Prioriteit 2 - Regelmatig\n",
    "    (\"Bergeend\", \"Tadorna tadorna\", \"bergeend\"),\n",
    "    (\"Blauwe Kiekendief\", \"Circus cyaneus\", \"blauwe_kiekendief\"),\n",
    "    (\"Bonte Strandloper\", \"Calidris alpina\", \"bonte_strandloper\"),\n",
    "    (\"Boomvalk\", \"Falco subbuteo\", \"boomvalk\"),\n",
    "    (\"Bosrietzanger\", \"Acrocephalus palustris\", \"bosrietzanger\"),\n",
    "    (\"Bosruiter\", \"Tringa glareola\", \"bosruiter\"),\n",
    "    (\"Braamsluiper\", \"Curruca curruca\", \"braamsluiper\"),\n",
    "    (\"Brilduiker\", \"Bucephala clangula\", \"brilduiker\"),\n",
    "    (\"Drieteenstrandloper\", \"Calidris alba\", \"drieteenstrandloper\"),\n",
    "    (\"Eider\", \"Somateria mollissima\", \"eider\"),\n",
    "    (\"Fluiter\", \"Phylloscopus sibilatrix\", \"fluiter\"),\n",
    "    (\"Gele Kwikstaart\", \"Motacilla flava\", \"gele_kwikstaart\"),\n",
    "    (\"Goudplevier\", \"Pluvialis apricaria\", \"goudplevier\"),\n",
    "    (\"Grasmus\", \"Curruca communis\", \"grasmus\"),\n",
    "    (\"Groenpootruiter\", \"Tringa nebularia\", \"groenpootruiter\"),\n",
    "    (\"Grote Gele Kwikstaart\", \"Motacilla cinerea\", \"grote_gele_kwikstaart\"),\n",
    "    (\"Grote Zaagbek\", \"Mergus merganser\", \"grote_zaagbek\"),\n",
    "    (\"IJsvogel\", \"Alcedo atthis\", \"ijsvogel\"),\n",
    "    (\"Kanoetstrandloper\", \"Calidris canutus\", \"kanoetstrandloper\"),\n",
    "    (\"Keep\", \"Fringilla montifringilla\", \"keep\"),\n",
    "    (\"Kemphaan\", \"Calidris pugnax\", \"kemphaan\"),\n",
    "    (\"Kleine Rietgans\", \"Anser brachyrhynchus\", \"kleine_rietgans\"),\n",
    "    (\"Kleine Strandloper\", \"Calidris minuta\", \"kleine_strandloper\"),\n",
    "    (\"Kluut\", \"Recurvirostra avosetta\", \"kluut\"),\n",
    "    (\"Koekoek\", \"Cuculus canorus\", \"koekoek\"),\n",
    "    (\"Mandarijneend\", \"Aix galericulata\", \"mandarijneend\"),\n",
    "    (\"Middelste Zaagbek\", \"Mergus serrator\", \"middelste_zaagbek\"),\n",
    "    (\"Nonnetje\", \"Mergellus albellus\", \"nonnetje\"),\n",
    "    (\"Oeverloper\", \"Actitis hypoleucos\", \"oeverloper\"),\n",
    "    (\"Paapje\", \"Saxicola rubetra\", \"paapje\"),\n",
    "    (\"Pijlstaart\", \"Anas acuta\", \"pijlstaart\"),\n",
    "    (\"Ransuil\", \"Asio otus\", \"ransuil\"),\n",
    "    (\"Regenwulp\", \"Numenius phaeopus\", \"regenwulp\"),\n",
    "    (\"Rietzanger\", \"Acrocephalus schoenobaenus\", \"rietzanger\"),\n",
    "    (\"Rode Wouw\", \"Milvus milvus\", \"rode_wouw\"),\n",
    "    (\"Roodhalsfuut\", \"Podiceps grisegena\", \"roodhalsfuut\"),\n",
    "    (\"Rosse Grutto\", \"Limosa lapponica\", \"rosse_grutto\"),\n",
    "    (\"Sijs\", \"Spinus spinus\", \"sijs\"),\n",
    "    (\"Slobeend\", \"Spatula clypeata\", \"slobeend\"),\n",
    "    (\"Smelleken\", \"Falco columbarius\", \"smelleken\"),\n",
    "    (\"Steenloper\", \"Arenaria interpres\", \"steenloper\"),\n",
    "    (\"Tafeleend\", \"Aythya ferina\", \"tafeleend\"),\n",
    "    (\"Tapuit\", \"Oenanthe oenanthe\", \"tapuit\"),\n",
    "    (\"Toendrarietgans\", \"Anser serrirostris\", \"toendrarietgans\"),\n",
    "    (\"Velduil\", \"Asio flammeus\", \"velduil\"),\n",
    "    (\"Watersnip\", \"Gallinago gallinago\", \"watersnip\"),\n",
    "    (\"Witgat\", \"Tringa ochropus\", \"witgat\"),\n",
    "    (\"Zwarte Ruiter\", \"Tringa erythropus\", \"zwarte_ruiter\"),\n",
    "    \n",
    "    # Prioriteit 3 - Minder algemeen (selectie)\n",
    "    (\"Barmsijs\", \"Acanthis flammea\", \"barmsijs\"),\n",
    "    (\"Beflijster\", \"Turdus torquatus\", \"beflijster\"),\n",
    "    (\"Bokje\", \"Lymnocryptes minimus\", \"bokje\"),\n",
    "    (\"Flamingo\", \"Phoenicopterus roseus\", \"flamingo\"),\n",
    "    (\"Grauwe Kiekendief\", \"Circus pygargus\", \"grauwe_kiekendief\"),\n",
    "    (\"Grauwe Klauwier\", \"Lanius collurio\", \"grauwe_klauwier\"),\n",
    "    (\"Klapekster\", \"Lanius excubitor\", \"klapekster\"),\n",
    "    (\"Kruisbek\", \"Loxia curvirostra\", \"kruisbek\"),\n",
    "    (\"Oehoe\", \"Bubo bubo\", \"oehoe\"),\n",
    "    (\"Snor\", \"Locustella luscinioides\", \"snor\"),\n",
    "]\n",
    "\n",
    "print(f\"Te trainen: {len(MISSING_SPECIES)} soorten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Xeno-canto API v3 met PARALLEL DOWNLOADS\nimport requests\nimport asyncio\nimport aiohttp\nimport aiofiles\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport json\n\ndef search_xeno_canto(scientific_name, voc_type='song', max_results=100):\n    \"\"\"Zoek opnames op Xeno-canto API v3.\"\"\"\n    parts = scientific_name.split()\n    if len(parts) < 2:\n        return []\n    \n    genus, species = parts[0].lower(), parts[1].lower()\n    \n    if ' ' in voc_type:\n        type_query = f'type:\"{voc_type}\"'\n    else:\n        type_query = f'type:{voc_type}'\n    \n    query = f'gen:{genus} sp:{species} {type_query} q:A'\n    url = f'https://xeno-canto.org/api/3/recordings?query={query}&key={XC_API_KEY}'\n    \n    try:\n        response = requests.get(url, timeout=30)\n        if response.status_code == 200:\n            return response.json().get('recordings', [])[:max_results]\n        elif response.status_code == 401:\n            print(f\"  ‚ùå 401 - Check API key!\")\n        return []\n    except Exception as e:\n        print(f\"  API error: {e}\")\n        return []\n\ndef download_single(args):\n    \"\"\"Download √©√©n opname (voor ThreadPoolExecutor).\"\"\"\n    recording, output_dir = args\n    xc_id = recording['id']\n    file_url = recording.get('file', '')\n    \n    if not file_url:\n        return None\n    \n    if file_url.startswith('//'):\n        file_url = 'https:' + file_url\n    elif not file_url.startswith('http'):\n        file_url = 'https://xeno-canto.org' + file_url\n    \n    output_path = output_dir / f\"XC{xc_id}.mp3\"\n    \n    if output_path.exists():\n        return output_path\n    \n    try:\n        response = requests.get(file_url, timeout=60)\n        if response.status_code == 200:\n            with open(output_path, 'wb') as f:\n                f.write(response.content)\n            return output_path\n    except:\n        pass\n    return None\n\ndef download_recordings_parallel(recordings, output_dir, max_workers=8):\n    \"\"\"Download meerdere opnames parallel.\"\"\"\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    downloaded = []\n    args_list = [(rec, output_dir) for rec in recordings]\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(download_single, args): args[0]['id'] for args in args_list}\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                downloaded.append(result)\n    \n    return downloaded\n\n# Test API\ndef test_api():\n    print(\"Testing Xeno-canto API v3...\")\n    query = 'gen:turdus sp:merula type:song q:A'\n    url = f'https://xeno-canto.org/api/3/recordings?query={query}&key={XC_API_KEY}'\n    try:\n        r = requests.get(url, timeout=10)\n        if r.status_code == 200:\n            n = r.json().get('numRecordings', 0)\n            print(f\"‚úÖ API werkt! ({n} Merel opnames gevonden)\")\n            return True\n        print(f\"‚ùå API error: {r.status_code}\")\n        return False\n    except Exception as e:\n        print(f\"‚ùå Error: {e}\")\n        return False\n\nif XC_API_KEY:\n    test_api()\nelse:\n    print(\"‚ö†Ô∏è Vul eerst je API key in!\")\n\nprint(\"\\n‚úÖ Parallel download functies geladen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Spectrogram generatie met PARALLEL PROCESSING\nimport librosa\nimport numpy as np\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom functools import partial\n\nSAMPLE_RATE = 48000\nN_MELS = 128\nN_FFT = 2048\nHOP_LENGTH = 512\nFMIN = 500\nFMAX = 8000\nSEGMENT_DURATION = 3.0\n\ndef process_single_audio(audio_path, max_segments=5):\n    \"\"\"Verwerk √©√©n audio bestand naar spectrogrammen.\"\"\"\n    try:\n        audio, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE, mono=True)\n    except:\n        return []\n    \n    segment_samples = int(SEGMENT_DURATION * SAMPLE_RATE)\n    spectrograms = []\n    \n    for i in range(0, len(audio), segment_samples):\n        if len(spectrograms) >= max_segments:\n            break\n        \n        segment = audio[i:i + segment_samples]\n        if len(segment) < segment_samples // 2:\n            continue\n        \n        if len(segment) < segment_samples:\n            segment = np.pad(segment, (0, segment_samples - len(segment)))\n        \n        mel_spec = librosa.feature.melspectrogram(\n            y=segment, sr=SAMPLE_RATE,\n            n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n            fmin=FMIN, fmax=FMAX\n        )\n        \n        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)\n        \n        if mel_norm.shape != (128, 128):\n            from skimage.transform import resize\n            mel_norm = resize(mel_norm, (128, 128), anti_aliasing=True)\n        \n        spectrograms.append(mel_norm)\n    \n    return spectrograms\n\ndef process_audio_files_parallel(audio_paths, max_segments=3, max_workers=4):\n    \"\"\"Verwerk meerdere audio bestanden parallel.\"\"\"\n    all_specs = []\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        func = partial(process_single_audio, max_segments=max_segments)\n        results = list(executor.map(func, audio_paths))\n    \n    for specs in results:\n        all_specs.extend(specs)\n    \n    return all_specs\n\nprint(\"‚úÖ Parallel spectrogram functies geladen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CNN Model met Mixed Precision Training (Stabiele versie)\nimport torch\nimport torch.nn as nn\n\n# Gebruik nieuwe autocast API (voorkomt deprecation warnings)\nif hasattr(torch, 'amp') and hasattr(torch.amp, 'autocast'):\n    from torch.amp import autocast, GradScaler\n    autocast_device = 'cuda'\nelse:\n    from torch.cuda.amp import autocast, GradScaler\n    autocast_device = None\n\nclass VocalizationCNN(nn.Module):\n    def __init__(self, input_shape=(128, 128), num_classes=3):\n        super().__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(0.25),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(0.25),\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(0.25),\n        )\n        \n        h, w = input_shape[0] // 8, input_shape[1] // 8\n        flatten_size = 128 * h * w\n        \n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(flatten_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Mixed precision scaler\nscaler = GradScaler() if USE_AMP else None\n\nprint(f\"‚úÖ Model klaar voor {device}\")\nif USE_AMP:\n    print(f\"‚úÖ Mixed Precision (FP16) actief\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GEOPTIMALISEERDE Training Pipeline (met label remapping fix)\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport time\n\ndef train_species_optimized(dutch_name, scientific_name, dirname):\n    \"\"\"\n    Geoptimaliseerde pipeline met label remapping voor ontbrekende klassen.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"üê¶ {dutch_name} ({scientific_name})\")\n    print(f\"{'='*60}\")\n    \n    start_time = time.time()\n    audio_dir = Path(f'{DRIVE_BASE}/audio/{dirname}')\n    \n    X_all, y_all = [], []\n    voc_types = [('song', 0), ('call', 1), ('alarm call', 2)]\n    available_types = []  # Track welke types we hebben\n    \n    # FASE 1: Download alle audio parallel per type\n    for voc_type, label in voc_types:\n        print(f\"  üì• {voc_type}...\", end=' ')\n        recordings = search_xeno_canto(scientific_name, voc_type, max_results=MAX_RECORDINGS_PER_TYPE)\n        \n        if not recordings:\n            print(\"0 gevonden\")\n            continue\n        \n        type_dir = audio_dir / voc_type.replace(' ', '_')\n        \n        audio_files = download_recordings_parallel(\n            recordings[:MAX_RECORDINGS_PER_TYPE], \n            type_dir, \n            max_workers=MAX_CONCURRENT_DOWNLOADS\n        )\n        print(f\"{len(audio_files)} gedownload\", end=' ')\n        \n        if audio_files:\n            specs = process_audio_files_parallel(audio_files, max_segments=3, max_workers=NUM_WORKERS)\n            if specs:  # Alleen toevoegen als we spectrograms hebben\n                for spec in specs:\n                    X_all.append(spec)\n                    y_all.append(label)\n                available_types.append((voc_type, label))\n            print(f\"‚Üí {len(specs)} specs\")\n        else:\n            print()\n    \n    # Check data\n    if len(X_all) < 30:\n        print(f\"  ‚ö†Ô∏è Te weinig data ({len(X_all)}), overslaan\")\n        return None, 'insufficient_data'\n    \n    X = np.array(X_all)\n    y = np.array(y_all)\n    \n    # === KRITIEKE FIX: Remap labels naar 0, 1, 2, ... ===\n    # Als we bijv. alleen call (1) en alarm (2) hebben, moeten labels 0 en 1 worden\n    unique_labels = np.unique(y)\n    num_classes = len(unique_labels)\n    \n    if num_classes < 2:\n        print(f\"  ‚ö†Ô∏è Slechts 1 klasse, overslaan\")\n        return None, 'single_class'\n    \n    # Maak label mapping\n    label_map = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n    y_remapped = np.array([label_map[label] for label in y])\n    \n    # Class names voor dit model\n    all_class_names = ['song', 'call', 'alarm']\n    class_names = [all_class_names[l] for l in unique_labels]\n    \n    unique, counts = np.unique(y_remapped, return_counts=True)\n    class_dist = {class_names[i]: int(counts[i]) for i in range(len(counts))}\n    print(f\"  üìä Data: {len(X)} specs, klassen: {class_dist}\")\n    \n    # Train/val split\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y_remapped, test_size=0.2, random_state=42, stratify=y_remapped\n    )\n    \n    # DataLoaders\n    train_dataset = TensorDataset(\n        torch.FloatTensor(X_train).unsqueeze(1),\n        torch.LongTensor(y_train)\n    )\n    val_dataset = TensorDataset(\n        torch.FloatTensor(X_val).unsqueeze(1),\n        torch.LongTensor(y_val)\n    )\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n        num_workers=NUM_WORKERS, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS, pin_memory=True\n    )\n    \n    # Model met correct aantal klassen\n    model = VocalizationCNN(num_classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    \n    # Training met error recovery\n    best_acc = 0\n    best_state = None\n    \n    try:\n        for epoch in range(EPOCHS):\n            model.train()\n            \n            for X_batch, y_batch in train_loader:\n                X_batch = X_batch.to(device, non_blocking=True)\n                y_batch = y_batch.to(device, non_blocking=True)\n                \n                optimizer.zero_grad()\n                \n                if USE_AMP and scaler is not None:\n                    if autocast_device:\n                        with autocast(device_type=autocast_device):\n                            outputs = model(X_batch)\n                            loss = criterion(outputs, y_batch)\n                    else:\n                        with autocast():\n                            outputs = model(X_batch)\n                            loss = criterion(outputs, y_batch)\n                    scaler.scale(loss).backward()\n                    scaler.step(optimizer)\n                    scaler.update()\n                else:\n                    outputs = model(X_batch)\n                    loss = criterion(outputs, y_batch)\n                    loss.backward()\n                    optimizer.step()\n            \n            # Validate\n            model.eval()\n            val_correct = 0\n            with torch.no_grad():\n                for X_batch, y_batch in val_loader:\n                    X_batch = X_batch.to(device, non_blocking=True)\n                    y_batch = y_batch.to(device, non_blocking=True)\n                    outputs = model(X_batch)\n                    val_correct += (outputs.argmax(1) == y_batch).sum().item()\n            \n            val_acc = val_correct / len(y_val)\n            if val_acc > best_acc:\n                best_acc = val_acc\n                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n                \n    except RuntimeError as e:\n        if 'CUDA' in str(e):\n            print(f\"  ‚ö†Ô∏è CUDA error, cleanup...\")\n            torch.cuda.empty_cache()\n            gc.collect()\n            if best_state is None:\n                return None, f'cuda_error: {str(e)[:30]}'\n        else:\n            raise e\n    \n    if best_state is None:\n        print(f\"  ‚ö†Ô∏è Training mislukt\")\n        return None, 'training_failed'\n    \n    # Save model met class_names voor inference\n    model_path = Path(f'{DRIVE_BASE}/models/{dirname}_cnn_{VERSION}.pt')\n    torch.save({\n        'model_state_dict': best_state,\n        'num_classes': num_classes,\n        'class_names': class_names,  # Belangrijk voor inference!\n        'label_map': label_map,\n        'accuracy': best_acc,\n        'species_name': dutch_name,\n        'scientific_name': scientific_name,\n        'version': VERSION,\n        'class_distribution': class_dist\n    }, model_path)\n    \n    # Cleanup GPU memory na elke soort\n    del model, train_loader, val_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    elapsed = time.time() - start_time\n    print(f\"  ‚úÖ {model_path.name} | Acc: {best_acc:.1%} | {elapsed:.0f}s\")\n    \n    return best_acc, 'success'\n\nprint(\"‚úÖ Training pipeline met label remapping geladen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üöÄ TRAIN ALLE SOORTEN (Geoptimaliseerd)\nfrom datetime import datetime\nimport pandas as pd\n\nresults = []\nstart_all = time.time()\n\nprint(f\"{'='*60}\")\nprint(f\"üöÄ EMSN Vocalization Training - Batch 2\")\nprint(f\"{'='*60}\")\nprint(f\"Start: {datetime.now().strftime('%H:%M:%S')}\")\nprint(f\"Soorten: {len(MISSING_SPECIES)}\")\nprint(f\"GPU: {GPU_TYPE} ({torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'})\")\nprint(f\"Batch size: {BATCH_SIZE} | Workers: {NUM_WORKERS} | AMP: {USE_AMP}\")\nprint(f\"{'='*60}\")\n\nsuccessful = 0\nfailed = 0\n\nfor i, (dutch, scientific, dirname) in enumerate(MISSING_SPECIES):\n    progress = f\"[{i+1}/{len(MISSING_SPECIES)}]\"\n    \n    try:\n        acc, status = train_species_optimized(dutch, scientific, dirname)\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'accuracy': acc,\n            'status': status\n        })\n        \n        if status == 'success':\n            successful += 1\n        else:\n            failed += 1\n            \n    except Exception as e:\n        print(f\"  ‚ùå Error: {str(e)[:60]}\")\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'accuracy': None,\n            'status': f'error: {str(e)[:40]}'\n        })\n        failed += 1\n    \n    # Checkpoint elke 10 soorten\n    if (i + 1) % 10 == 0:\n        pd.DataFrame(results).to_csv(\n            f'{DRIVE_BASE}/training_batch2_checkpoint.csv', index=False\n        )\n        elapsed = time.time() - start_all\n        remaining = (elapsed / (i + 1)) * (len(MISSING_SPECIES) - i - 1)\n        print(f\"\\n  üíæ Checkpoint | ‚úÖ {successful} | ‚ùå {failed} | ETA: {remaining/60:.0f}min\\n\")\n\n# Eindresultaat\nelapsed_all = time.time() - start_all\nprint(f\"\\n{'='*60}\")\nprint(f\"üèÅ TRAINING VOLTOOID!\")\nprint(f\"{'='*60}\")\nprint(f\"Tijd: {elapsed_all/60:.1f} minuten\")\nprint(f\"Succesvol: {successful}/{len(MISSING_SPECIES)}\")\nprint(f\"Mislukt: {failed}/{len(MISSING_SPECIES)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üìä Resultaten Samenvatting\nimport pandas as pd\n\ndf = pd.DataFrame(results)\ndf.to_csv(f'{DRIVE_BASE}/training_results_batch2_{VERSION}.csv', index=False)\n\nsuccessful_df = df[df['status'] == 'success']\n\nprint(f\"\\n{'='*60}\")\nprint(f\"üìä RESULTATEN BATCH 2\")\nprint(f\"{'='*60}\")\nprint(f\"Getraind: {len(successful_df)}/{len(df)} soorten\")\n\nif len(successful_df) > 0:\n    print(f\"\\nAccuracy statistieken:\")\n    print(f\"  Gemiddeld: {successful_df['accuracy'].mean():.1%}\")\n    print(f\"  Minimum:   {successful_df['accuracy'].min():.1%}\")\n    print(f\"  Maximum:   {successful_df['accuracy'].max():.1%}\")\n    \n    print(f\"\\nüèÜ Top 10 beste modellen:\")\n    top10 = successful_df.nlargest(10, 'accuracy')[['species', 'accuracy']]\n    for _, row in top10.iterrows():\n        print(f\"  {row['accuracy']:.1%} - {row['species']}\")\n\nfailed_df = df[df['status'] != 'success']\nif len(failed_df) > 0:\n    print(f\"\\n‚ö†Ô∏è Mislukte soorten ({len(failed_df)}):\")\n    for _, row in failed_df.iterrows():\n        print(f\"  {row['species']}: {row['status']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üì• DOWNLOAD MODELLEN (belangrijk - data verdwijnt na sessie!)\nfrom pathlib import Path\nfrom google.colab import files\nimport shutil\n\nmodels_dir = Path(f'{DRIVE_BASE}/models')\nmodels = sorted(models_dir.glob('*.pt'))\n\nprint(f\"{'='*60}\")\nprint(f\"üìÅ GETRAINDE MODELLEN\")\nprint(f\"{'='*60}\")\nprint(f\"Totaal: {len(models)} modellen\")\n\nif models:\n    # Bereken totale grootte\n    total_size = sum(m.stat().st_size for m in models) / 1e6\n    print(f\"Grootte: {total_size:.1f} MB\")\n    \n    # Maak ZIP bestand\n    print(f\"\\nüì¶ ZIP bestand maken...\")\n    zip_path = '/content/emsn_models_batch2.zip'\n    shutil.make_archive('/content/emsn_models_batch2', 'zip', models_dir)\n    zip_size = Path(zip_path).stat().st_size / 1e6\n    print(f\"‚úÖ {zip_path} ({zip_size:.1f} MB)\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"üì• DOWNLOAD OPTIES\")\n    print(f\"{'='*60}\")\n    print(\"\"\"\nOPTIE 1: Download ZIP (klik op link hieronder)\n\"\"\")\n    # Automatische download trigger\n    files.download(zip_path)\n    \n    print(\"\"\"\nOPTIE 2: Kopieer naar Pi via terminal\n   - Open nieuwe terminal in Colab\n   - Run: scp /content/emsn_models_batch2.zip ronny@192.168.1.178:~/\n   \nOPTIE 3: Upload naar Google Drive (als je ruimte hebt vrijgemaakt)\n   from google.colab import drive\n   drive.mount('/content/drive')\n   !cp /content/emsn_models_batch2.zip /content/drive/MyDrive/\n\"\"\")\nelse:\n    print(\"‚ö†Ô∏è Geen modellen gevonden. Run eerst de training.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}