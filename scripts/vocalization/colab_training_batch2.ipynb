{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSN 2.0 - Vocalization Classifier Training Batch 2\n",
    "\n",
    "Train de **92 ontbrekende soorten** met GPU acceleratie.\n",
    "\n",
    "## Deze batch bevat:\n",
    "- 3 Prioriteit 1 soorten (Kauw, Kokmeeuw, Nijlgans)\n",
    "- 47 Prioriteit 2 soorten\n",
    "- 42 Prioriteit 3 soorten\n",
    "\n",
    "**Geschatte tijd:** 2-4 uur op Colab GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install librosa scikit-learn scikit-image matplotlib tqdm requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_BASE = '/content/drive/MyDrive/EMSN-Vocalization'\n",
    "os.makedirs(f'{DRIVE_BASE}/models', exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_BASE}/audio', exist_ok=True)\n",
    "os.makedirs(f'{DRIVE_BASE}/spectrograms', exist_ok=True)\n",
    "print(f\"Drive base: {DRIVE_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATIE ===\n",
    "VERSION = '2025'\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "MIN_SAMPLES = 50  # Minimum per vocalisatie type\n",
    "\n",
    "# Xeno-canto API key (optioneel maar aanbevolen)\n",
    "XC_API_KEY = ''  # Vul in als je een API key hebt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontbrekende soorten voor batch 2\n",
    "# Format: (Nederlandse naam, Wetenschappelijke naam, directory_naam)\n",
    "\n",
    "MISSING_SPECIES = [\n",
    "    # Prioriteit 1 - ZEER BELANGRIJK\n",
    "    (\"Kauw\", \"Coloeus monedula\", \"kauw\"),\n",
    "    (\"Kokmeeuw\", \"Chroicocephalus ridibundus\", \"kokmeeuw\"),\n",
    "    (\"Nijlgans\", \"Alopochen aegyptiaca\", \"nijlgans\"),\n",
    "    \n",
    "    # Prioriteit 2 - Regelmatig\n",
    "    (\"Bergeend\", \"Tadorna tadorna\", \"bergeend\"),\n",
    "    (\"Blauwe Kiekendief\", \"Circus cyaneus\", \"blauwe_kiekendief\"),\n",
    "    (\"Bonte Strandloper\", \"Calidris alpina\", \"bonte_strandloper\"),\n",
    "    (\"Boomvalk\", \"Falco subbuteo\", \"boomvalk\"),\n",
    "    (\"Bosrietzanger\", \"Acrocephalus palustris\", \"bosrietzanger\"),\n",
    "    (\"Bosruiter\", \"Tringa glareola\", \"bosruiter\"),\n",
    "    (\"Braamsluiper\", \"Curruca curruca\", \"braamsluiper\"),\n",
    "    (\"Brilduiker\", \"Bucephala clangula\", \"brilduiker\"),\n",
    "    (\"Drieteenstrandloper\", \"Calidris alba\", \"drieteenstrandloper\"),\n",
    "    (\"Eider\", \"Somateria mollissima\", \"eider\"),\n",
    "    (\"Fluiter\", \"Phylloscopus sibilatrix\", \"fluiter\"),\n",
    "    (\"Gele Kwikstaart\", \"Motacilla flava\", \"gele_kwikstaart\"),\n",
    "    (\"Goudplevier\", \"Pluvialis apricaria\", \"goudplevier\"),\n",
    "    (\"Grasmus\", \"Curruca communis\", \"grasmus\"),\n",
    "    (\"Groenpootruiter\", \"Tringa nebularia\", \"groenpootruiter\"),\n",
    "    (\"Grote Gele Kwikstaart\", \"Motacilla cinerea\", \"grote_gele_kwikstaart\"),\n",
    "    (\"Grote Zaagbek\", \"Mergus merganser\", \"grote_zaagbek\"),\n",
    "    (\"IJsvogel\", \"Alcedo atthis\", \"ijsvogel\"),\n",
    "    (\"Kanoetstrandloper\", \"Calidris canutus\", \"kanoetstrandloper\"),\n",
    "    (\"Keep\", \"Fringilla montifringilla\", \"keep\"),\n",
    "    (\"Kemphaan\", \"Calidris pugnax\", \"kemphaan\"),\n",
    "    (\"Kleine Rietgans\", \"Anser brachyrhynchus\", \"kleine_rietgans\"),\n",
    "    (\"Kleine Strandloper\", \"Calidris minuta\", \"kleine_strandloper\"),\n",
    "    (\"Kluut\", \"Recurvirostra avosetta\", \"kluut\"),\n",
    "    (\"Koekoek\", \"Cuculus canorus\", \"koekoek\"),\n",
    "    (\"Mandarijneend\", \"Aix galericulata\", \"mandarijneend\"),\n",
    "    (\"Middelste Zaagbek\", \"Mergus serrator\", \"middelste_zaagbek\"),\n",
    "    (\"Nonnetje\", \"Mergellus albellus\", \"nonnetje\"),\n",
    "    (\"Oeverloper\", \"Actitis hypoleucos\", \"oeverloper\"),\n",
    "    (\"Paapje\", \"Saxicola rubetra\", \"paapje\"),\n",
    "    (\"Pijlstaart\", \"Anas acuta\", \"pijlstaart\"),\n",
    "    (\"Ransuil\", \"Asio otus\", \"ransuil\"),\n",
    "    (\"Regenwulp\", \"Numenius phaeopus\", \"regenwulp\"),\n",
    "    (\"Rietzanger\", \"Acrocephalus schoenobaenus\", \"rietzanger\"),\n",
    "    (\"Rode Wouw\", \"Milvus milvus\", \"rode_wouw\"),\n",
    "    (\"Roodhalsfuut\", \"Podiceps grisegena\", \"roodhalsfuut\"),\n",
    "    (\"Rosse Grutto\", \"Limosa lapponica\", \"rosse_grutto\"),\n",
    "    (\"Sijs\", \"Spinus spinus\", \"sijs\"),\n",
    "    (\"Slobeend\", \"Spatula clypeata\", \"slobeend\"),\n",
    "    (\"Smelleken\", \"Falco columbarius\", \"smelleken\"),\n",
    "    (\"Steenloper\", \"Arenaria interpres\", \"steenloper\"),\n",
    "    (\"Tafeleend\", \"Aythya ferina\", \"tafeleend\"),\n",
    "    (\"Tapuit\", \"Oenanthe oenanthe\", \"tapuit\"),\n",
    "    (\"Toendrarietgans\", \"Anser serrirostris\", \"toendrarietgans\"),\n",
    "    (\"Velduil\", \"Asio flammeus\", \"velduil\"),\n",
    "    (\"Watersnip\", \"Gallinago gallinago\", \"watersnip\"),\n",
    "    (\"Witgat\", \"Tringa ochropus\", \"witgat\"),\n",
    "    (\"Zwarte Ruiter\", \"Tringa erythropus\", \"zwarte_ruiter\"),\n",
    "    \n",
    "    # Prioriteit 3 - Minder algemeen (selectie)\n",
    "    (\"Barmsijs\", \"Acanthis flammea\", \"barmsijs\"),\n",
    "    (\"Beflijster\", \"Turdus torquatus\", \"beflijster\"),\n",
    "    (\"Bokje\", \"Lymnocryptes minimus\", \"bokje\"),\n",
    "    (\"Flamingo\", \"Phoenicopterus roseus\", \"flamingo\"),\n",
    "    (\"Grauwe Kiekendief\", \"Circus pygargus\", \"grauwe_kiekendief\"),\n",
    "    (\"Grauwe Klauwier\", \"Lanius collurio\", \"grauwe_klauwier\"),\n",
    "    (\"Klapekster\", \"Lanius excubitor\", \"klapekster\"),\n",
    "    (\"Kruisbek\", \"Loxia curvirostra\", \"kruisbek\"),\n",
    "    (\"Oehoe\", \"Bubo bubo\", \"oehoe\"),\n",
    "    (\"Snor\", \"Locustella luscinioides\", \"snor\"),\n",
    "]\n",
    "\n",
    "print(f\"Te trainen: {len(MISSING_SPECIES)} soorten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xeno-canto API functies\n",
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def search_xeno_canto(scientific_name, voc_type='song', max_results=100):\n",
    "    \"\"\"\n",
    "    Zoek opnames op Xeno-canto.\n",
    "    voc_type: 'song', 'call', of 'alarm call'\n",
    "    \"\"\"\n",
    "    # Xeno-canto v3 API\n",
    "    base_url = 'https://xeno-canto.org/api/3/recordings'\n",
    "    \n",
    "    params = {\n",
    "        'query': f'{scientific_name} type:{voc_type} q:A',  # Alleen kwaliteit A\n",
    "    }\n",
    "    \n",
    "    headers = {}\n",
    "    if XC_API_KEY:\n",
    "        headers['X-API-KEY'] = XC_API_KEY\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        recordings = data.get('recordings', [])\n",
    "        return recordings[:max_results]\n",
    "    except Exception as e:\n",
    "        print(f\"  API error: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_recording(recording, output_dir):\n",
    "    \"\"\"Download een opname van Xeno-canto.\"\"\"\n",
    "    xc_id = recording['id']\n",
    "    file_url = recording.get('file')\n",
    "    \n",
    "    if not file_url:\n",
    "        return None\n",
    "    \n",
    "    # Fix URL (soms relatief)\n",
    "    if file_url.startswith('//'):\n",
    "        file_url = 'https:' + file_url\n",
    "    elif not file_url.startswith('http'):\n",
    "        file_url = 'https://xeno-canto.org' + file_url\n",
    "    \n",
    "    output_path = output_dir / f\"XC{xc_id}.mp3\"\n",
    "    \n",
    "    if output_path.exists():\n",
    "        return output_path\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(file_url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"  Download error XC{xc_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Xeno-canto functies geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram generatie\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "SAMPLE_RATE = 48000\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "FMIN = 500\n",
    "FMAX = 8000\n",
    "SEGMENT_DURATION = 3.0\n",
    "\n",
    "def audio_to_spectrograms(audio_path, max_segments=5):\n",
    "    \"\"\"Converteer audio naar mel-spectrogrammen.\"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE, mono=True)\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    \n",
    "    segment_samples = int(SEGMENT_DURATION * SAMPLE_RATE)\n",
    "    spectrograms = []\n",
    "    \n",
    "    # Splits in segmenten\n",
    "    for i in range(0, len(audio), segment_samples):\n",
    "        if len(spectrograms) >= max_segments:\n",
    "            break\n",
    "        \n",
    "        segment = audio[i:i + segment_samples]\n",
    "        \n",
    "        if len(segment) < segment_samples // 2:\n",
    "            continue\n",
    "        \n",
    "        # Pad indien nodig\n",
    "        if len(segment) < segment_samples:\n",
    "            segment = np.pad(segment, (0, segment_samples - len(segment)))\n",
    "        \n",
    "        # Mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=segment, sr=SAMPLE_RATE,\n",
    "            n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "            fmin=FMIN, fmax=FMAX\n",
    "        )\n",
    "        \n",
    "        # Naar dB en normaliseer\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)\n",
    "        \n",
    "        # Resize naar 128x128\n",
    "        if mel_norm.shape != (128, 128):\n",
    "            from skimage.transform import resize\n",
    "            mel_norm = resize(mel_norm, (128, 128), anti_aliasing=True)\n",
    "        \n",
    "        spectrograms.append(mel_norm)\n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "print(\"Spectrogram functies geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VocalizationCNN(nn.Module):\n",
    "    def __init__(self, input_shape=(128, 128), num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        h, w = input_shape[0] // 8, input_shape[1] // 8\n",
    "        flatten_size = 128 * h * w\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flatten_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete training pipeline voor Ã©Ã©n soort\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "def train_species_complete(dutch_name, scientific_name, dirname):\n",
    "    \"\"\"\n",
    "    Complete pipeline: download -> spectrograms -> train -> save.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {dutch_name} ({scientific_name})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    audio_dir = Path(f'{DRIVE_BASE}/audio/{dirname}')\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    X_all, y_all = [], []\n",
    "    voc_types = [('song', 0), ('call', 1), ('alarm call', 2)]\n",
    "    \n",
    "    # Download en verwerk per vocalisatie type\n",
    "    for voc_type, label in voc_types:\n",
    "        print(f\"  Zoeken: {voc_type}...\")\n",
    "        recordings = search_xeno_canto(scientific_name, voc_type, max_results=30)\n",
    "        print(f\"    Gevonden: {len(recordings)} opnames\")\n",
    "        \n",
    "        if not recordings:\n",
    "            continue\n",
    "        \n",
    "        type_dir = audio_dir / voc_type.replace(' ', '_')\n",
    "        type_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        specs_count = 0\n",
    "        for rec in recordings[:20]:  # Max 20 opnames per type\n",
    "            audio_path = download_recording(rec, type_dir)\n",
    "            if audio_path:\n",
    "                specs = audio_to_spectrograms(audio_path, max_segments=3)\n",
    "                for spec in specs:\n",
    "                    X_all.append(spec)\n",
    "                    y_all.append(label)\n",
    "                    specs_count += 1\n",
    "            \n",
    "            time.sleep(0.5)  # Rate limiting\n",
    "        \n",
    "        print(f\"    Spectrogrammen: {specs_count}\")\n",
    "    \n",
    "    # Check of we genoeg data hebben\n",
    "    X = np.array(X_all)\n",
    "    y = np.array(y_all)\n",
    "    \n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n  Totaal: {len(X)} spectrogrammen\")\n",
    "    print(f\"  Klassen: {dict(zip(['song', 'call', 'alarm'], counts))}\")\n",
    "    \n",
    "    if len(X) < 50 or len(unique) < 2:\n",
    "        print(f\"  âš ï¸ Te weinig data, overslaan\")\n",
    "        return None, 'insufficient_data'\n",
    "    \n",
    "    # Train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Naar tensors\n",
    "    X_train_t = torch.FloatTensor(X_train).unsqueeze(1)\n",
    "    X_val_t = torch.FloatTensor(X_val).unsqueeze(1)\n",
    "    y_train_t = torch.LongTensor(y_train)\n",
    "    y_val_t = torch.LongTensor(y_val)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train_t, y_train_t),\n",
    "        batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        TensorDataset(X_val_t, y_val_t),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = VocalizationCNN(num_classes=len(unique)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                val_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "        \n",
    "        val_acc = val_correct / len(y_val)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{EPOCHS} - val_acc: {val_acc:.1%}\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = Path(f'{DRIVE_BASE}/models/{dirname}_cnn_{VERSION}.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'num_classes': len(unique),\n",
    "        'accuracy': best_acc,\n",
    "        'species_name': dutch_name,\n",
    "        'scientific_name': scientific_name,\n",
    "        'version': VERSION\n",
    "    }, model_path)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n  âœ… Model opgeslagen: {model_path.name}\")\n",
    "    print(f\"  Accuracy: {best_acc:.1%}\")\n",
    "    print(f\"  Tijd: {elapsed/60:.1f} minuten\")\n",
    "    \n",
    "    return best_acc, 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN ALLE ONTBREKENDE SOORTEN\n",
    "from datetime import datetime\n",
    "\n",
    "results = []\n",
    "start_all = time.time()\n",
    "\n",
    "print(f\"Start: {datetime.now()}\")\n",
    "print(f\"Soorten: {len(MISSING_SPECIES)}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print()\n",
    "\n",
    "for i, (dutch, scientific, dirname) in enumerate(MISSING_SPECIES):\n",
    "    print(f\"\\n[{i+1}/{len(MISSING_SPECIES)}]\", end='')\n",
    "    \n",
    "    try:\n",
    "        acc, status = train_species_complete(dutch, scientific, dirname)\n",
    "        results.append({\n",
    "            'species': dutch,\n",
    "            'scientific': scientific,\n",
    "            'accuracy': acc,\n",
    "            'status': status\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error: {e}\")\n",
    "        results.append({\n",
    "            'species': dutch,\n",
    "            'scientific': scientific,\n",
    "            'accuracy': None,\n",
    "            'status': f'error: {str(e)[:50]}'\n",
    "        })\n",
    "    \n",
    "    # Tussentijds opslaan\n",
    "    if (i + 1) % 10 == 0:\n",
    "        import pandas as pd\n",
    "        pd.DataFrame(results).to_csv(\n",
    "            f'{DRIVE_BASE}/training_results_batch2_checkpoint.csv',\n",
    "            index=False\n",
    "        )\n",
    "        print(f\"\\n  ðŸ“ Checkpoint opgeslagen\")\n",
    "\n",
    "elapsed_all = time.time() - start_all\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"KLAAR!\")\n",
    "print(f\"Totale tijd: {elapsed_all/3600:.1f} uur\")\n",
    "print(f\"Succesvol: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"Mislukt: {sum(1 for r in results if r['status'] != 'success')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultaten opslaan\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'{DRIVE_BASE}/training_results_batch2_{VERSION}.csv', index=False)\n",
    "\n",
    "successful = df[df['status'] == 'success']\n",
    "print(f\"\\nSamenvatting:\")\n",
    "print(f\"  Getraind: {len(successful)} soorten\")\n",
    "if len(successful) > 0:\n",
    "    print(f\"  Gem. accuracy: {successful['accuracy'].mean():.1%}\")\n",
    "    print(f\"  Min accuracy: {successful['accuracy'].min():.1%}\")\n",
    "    print(f\"  Max accuracy: {successful['accuracy'].max():.1%}\")\n",
    "    print(f\"\\nTop 10:\")\n",
    "    print(successful.nlargest(10, 'accuracy')[['species', 'accuracy']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hoeveel modellen er nu zijn\n",
    "models_dir = Path(f'{DRIVE_BASE}/models')\n",
    "models = list(models_dir.glob('*.pt'))\n",
    "print(f\"\\nModellen in Drive: {len(models)}\")\n",
    "print(f\"\\nGebruik rclone om te syncen naar je Pi:\")\n",
    "print(f\"  rclone sync gdrive:EMSN-Vocalization/models/ ~/emsn-vocalization/trained-models/ -P\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
