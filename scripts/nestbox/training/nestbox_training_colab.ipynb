{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nestkast Occupancy Model Training - EMSN2\n",
    "\n",
    "Train een MobileNetV2 model voor nestkast bezetting detectie.\n",
    "\n",
    "**Features:**\n",
    "- Data augmentatie (rotatie, kleur, flip, etc.)\n",
    "- Transfer learning van ImageNet\n",
    "- Mixed precision training (sneller op Colab GPU)\n",
    "\n",
    "**Data:**\n",
    "- Leeg: daglicht beelden van alle nestkasten\n",
    "- Bezet: nachtbeelden met Koolmees (IR camera)\n",
    "\n",
    "**Auteur:** EMSN2 / Claude Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuratie - pas aan naar jouw Drive pad\n",
    "DRIVE_BASE = '/content/drive/MyDrive/EMSN/nestbox-training'\n",
    "DATA_DIR = f'{DRIVE_BASE}/data'\n",
    "OUTPUT_DIR = f'{DRIVE_BASE}/models'\n",
    "\n",
    "# Check data\n",
    "import os\n",
    "print(f\"Leeg beelden: {len(os.listdir(f'{DATA_DIR}/leeg'))}\")\n",
    "print(f\"Bezet beelden: {len(os.listdir(f'{DATA_DIR}/bezet'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentatie\n",
    "\n",
    "Uitgebreide augmentatie voor robuustheid:\n",
    "- **Rotatie**: -15° tot +15° (camera kan scheef hangen)\n",
    "- **Kleurvariatie**: brightness, contrast, saturation (daglicht vs IR)\n",
    "- **Flip**: horizontaal (vogel kan beide kanten op zitten)\n",
    "- **Affine**: kleine schaal/translatie variaties\n",
    "- **Grayscale**: soms IR, soms kleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "# Uitgebreide augmentatie voor training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE + 32, INPUT_SIZE + 32)),  # Iets groter voor crop\n",
    "    transforms.RandomCrop(INPUT_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),  # Camera kan scheef hangen\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.1, 0.1),  # Kleine verschuiving\n",
    "        scale=(0.9, 1.1)       # Kleine schaalvariatie\n",
    "    ),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.3,   # Variatie in belichting\n",
    "        contrast=0.3,     # IR vs daglicht contrast\n",
    "        saturation=0.3,   # Kleurverzadiging\n",
    "        hue=0.1           # Kleine kleurverschuiving\n",
    "    ),\n",
    "    transforms.RandomGrayscale(p=0.2),  # Soms IR-achtig\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),  # Lichte blur\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))  # Random occlusion\n",
    "])\n",
    "\n",
    "# Simpele transform voor validatie\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"Transforms gedefinieerd met uitgebreide augmentatie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestboxDataset(Dataset):\n",
    "    \"\"\"Dataset voor nestkast beelden\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.classes = ['leeg', 'bezet']\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.data_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for img_path in class_dir.glob('*.jpg'):\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"Dataset: {len(self.samples)} beelden geladen\")\n",
    "        for c in self.classes:\n",
    "            count = sum(1 for _, label in self.samples if label == self.class_to_idx[c])\n",
    "            print(f\"  - {c}: {count}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Laad dataset\n",
    "full_dataset = NestboxDataset(DATA_DIR, transform=None)  # Transform later\n",
    "\n",
    "# Split in train/val\n",
    "train_size = int(TRAIN_SPLIT * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_indices, val_indices = random_split(\n",
    "    range(len(full_dataset)), \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(train_indices)}, Validation: {len(val_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"Subset met aparte transform\"\"\"\n",
    "    def __init__(self, dataset, indices, transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = list(indices)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.dataset.samples[self.indices[idx]]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Maak train/val datasets met juiste transforms\n",
    "train_dataset = SubsetWithTransform(full_dataset, train_indices, train_transform)\n",
    "val_dataset = SubsetWithTransform(full_dataset, val_indices, val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiseer Augmentatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toon voorbeelden van augmentatie\n",
    "def show_augmented_samples(dataset, n_samples=4, n_augments=4):\n",
    "    \"\"\"Toon origineel en geaugmenteerde versies\"\"\"\n",
    "    fig, axes = plt.subplots(n_samples, n_augments + 1, figsize=(15, 3*n_samples))\n",
    "    \n",
    "    # Inverse normalisatie voor visualisatie\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "        std=[1/0.229, 1/0.224, 1/0.225]\n",
    "    )\n",
    "    \n",
    "    indices = np.random.choice(len(full_dataset), n_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img_path, label = full_dataset.samples[idx]\n",
    "        orig_img = Image.open(img_path).convert('RGB')\n",
    "        class_name = full_dataset.classes[label]\n",
    "        \n",
    "        # Origineel\n",
    "        axes[i, 0].imshow(orig_img)\n",
    "        axes[i, 0].set_title(f'Origineel ({class_name})')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Augmentaties\n",
    "        for j in range(n_augments):\n",
    "            aug_img = train_transform(orig_img)\n",
    "            aug_img = inv_normalize(aug_img)\n",
    "            aug_img = torch.clamp(aug_img, 0, 1)\n",
    "            axes[i, j+1].imshow(aug_img.permute(1, 2, 0))\n",
    "            axes[i, j+1].set_title(f'Aug {j+1}')\n",
    "            axes[i, j+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_augmented_samples(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=2):\n",
    "    \"\"\"MobileNetV2 met custom classifier\"\"\"\n",
    "    # Pretrained MobileNetV2\n",
    "    model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Freeze early layers (optioneel - kan uitgecomment worden voor full fine-tuning)\n",
    "    for param in model.features[:10].parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Custom classifier\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model(num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Trainable parameters\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss en optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Mixed precision voor snellere training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(\"Optimizer en scheduler geconfigureerd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"Train voor één epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass met scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Valideer model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"Start training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        marker = ' ⭐ BEST'\n",
    "    else:\n",
    "        marker = ''\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.1f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.1f}%{marker}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training voltooid! Beste validatie accuracy: {best_val_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['val_acc'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Opslaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad beste model\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Maak output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "model_filename = f'nestbox_model_{timestamp}.pt'\n",
    "model_path = f'{OUTPUT_DIR}/{model_filename}'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'classes': ['leeg', 'bezet'],\n",
    "    'input_size': INPUT_SIZE,\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'epochs_trained': NUM_EPOCHS,\n",
    "    'augmentation': 'extensive',\n",
    "    'training_date': timestamp\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model opgeslagen: {model_path}\")\n",
    "print(f\"Beste validatie accuracy: {best_val_acc:.1f}%\")\n",
    "\n",
    "# Kopieer ook als 'latest'\n",
    "import shutil\n",
    "shutil.copy(model_path, f'{OUTPUT_DIR}/nestbox_model_latest.pt')\n",
    "print(f\"Gekopieerd naar: {OUTPUT_DIR}/nestbox_model_latest.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test op enkele beelden\n",
    "def predict_and_show(model, dataset, n_samples=8):\n",
    "    \"\"\"Voorspel en toon resultaten\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_samples//2, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "        std=[1/0.229, 1/0.224, 1/0.225]\n",
    "    )\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        true_class = full_dataset.classes[label]\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred_idx = probs.argmax(1).item()\n",
    "            confidence = probs[0, pred_idx].item()\n",
    "        \n",
    "        pred_class = full_dataset.classes[pred_idx]\n",
    "        \n",
    "        # Show\n",
    "        img_show = inv_normalize(image)\n",
    "        img_show = torch.clamp(img_show, 0, 1)\n",
    "        axes[i].imshow(img_show.permute(1, 2, 0))\n",
    "        \n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        axes[i].set_title(f'True: {true_class}\\nPred: {pred_class} ({confidence:.0%})', color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "predict_and_show(model, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Verzamel alle voorspellingen\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['leeg', 'bezet'],\n",
    "            yticklabels=['leeg', 'bezet'])\n",
    "plt.xlabel('Voorspeld')\n",
    "plt.ylabel('Werkelijk')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['leeg', 'bezet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model\n",
    "\n",
    "Na training kun je het model downloaden naar je Pi via rclone of direct kopiëren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING VOLTOOID\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nModel opgeslagen in: {OUTPUT_DIR}\")\n",
    "print(f\"Beste accuracy: {best_val_acc:.1f}%\")\n",
    "print(f\"\\nKopieer naar Pi met:\")\n",
    "print(f\"  rclone copy gdrive:EMSN/nestbox-training/models/nestbox_model_latest.pt /mnt/nas-birdnet-archive/nestbox/models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
