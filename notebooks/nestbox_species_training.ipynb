{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSN Nestkast Species Training - Januari 2026\n",
    "\n",
    "**Probleem:** AI model herkent slapende Koolmees niet (92.7% 'leeg' ipv 'koolmees')\n",
    "\n",
    "**Oorzaak:** Model getraind met slechts 112 samples\n",
    "\n",
    "**Oplossing:** Hertrainen met 814+ samples:\n",
    "- 275 koolmees screenshots (midden nestkast dec/jan)\n",
    "- 539 leeg screenshots (voor+achter nestkast dec/jan)\n",
    "\n",
    "## Data staat klaar op Google Drive!\n",
    "Gewoon alle cellen runnen - geen upload nodig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Check\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Data staat klaar op Drive\n",
    "import os\n",
    "DATA_DIR = '/content/drive/MyDrive/EMSN/nestbox_training'\n",
    "\n",
    "print(\"\\n=== Training Data ===\")\n",
    "for cls in os.listdir(DATA_DIR):\n",
    "    path = os.path.join(DATA_DIR, cls)\n",
    "    if os.path.isdir(path):\n",
    "        count = len([f for f in os.listdir(path) if f.endswith('.jpg')])\n",
    "        print(f\"{cls}: {count} afbeeldingen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestboxDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.classes = sorted([d.name for d in self.data_dir.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = self.data_dir / cls_name\n",
    "            for img_path in cls_dir.glob('*.jpg'):\n",
    "                self.samples.append((img_path, self.class_to_idx[cls_name]))\n",
    "        \n",
    "        print(f\"Classes: {self.classes}\")\n",
    "        print(f\"Total: {len(self.samples)} samples\")\n",
    "        for cls in self.classes:\n",
    "            count = sum(1 for s in self.samples if self.classes[s[1]] == cls)\n",
    "            print(f\"  {cls}: {count}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = NestboxDataset(DATA_DIR, transform=train_transform)\n",
    "classes = full_dataset.classes\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"\\nTrain: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bekijk voorbeelden\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i, (img, label) in enumerate(train_dataset):\n",
    "    if i >= 8: break\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    img_np = img.numpy().transpose(1, 2, 0)\n",
    "    img_np = img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    ax.imshow(img_np)\n",
    "    ax.set_title(classes[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes):\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for param in list(model.parameters())[:-20]:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Custom classifier\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model(len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "print(f\"Model: MobileNetV2, Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training!\n",
    "best_val_acc = 0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "patience_counter = 0\n",
    "PATIENCE = 7\n",
    "\n",
    "# Model wordt opgeslagen op Drive\n",
    "MODEL_SAVE_PATH = '/content/drive/MyDrive/EMSN/nestbox_training/nestbox_species_model.pt'\n",
    "\n",
    "print(f\"Training {EPOCHS} epochs...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'classes': classes,\n",
    "            'num_classes': len(classes),\n",
    "            'architecture': 'mobilenet_v2',\n",
    "            'input_size': INPUT_SIZE,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'train_samples': len(train_dataset),\n",
    "            'val_samples': len(val_dataset),\n",
    "            'epochs': epoch + 1,\n",
    "            'trained_at': str(np.datetime64('now')),\n",
    "            'model_type': 'species_detector',\n",
    "            'supports_day_night': True\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        marker = ' *BEST* (saved to Drive)'\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        marker = ''\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{EPOCHS}: Train Loss={train_loss:.4f} Acc={train_acc:.1f}% | Val Loss={val_loss:.4f} Acc={val_acc:.1f}%{marker}\")\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best validation accuracy: {best_val_acc:.1f}%\")\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(history['train_loss'], label='Train')\n",
    "ax1.plot(history['val_loss'], label='Val')\n",
    "ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.set_title('Loss')\n",
    "ax2.plot(history['train_acc'], label='Train')\n",
    "ax2.plot(history['val_acc'], label='Val')\n",
    "ax2.set_xlabel('Epoch'); ax2.set_ylabel('Accuracy %'); ax2.legend(); ax2.set_title('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load best\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Info & Installatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model info\n",
    "import os\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL INFO\")\n",
    "print(\"=\" * 50)\n",
    "for k, v in checkpoint.items():\n",
    "    if k != 'model_state_dict':\n",
    "        print(f\"{k}: {v}\")\n",
    "print(f\"\\nFile: {os.path.getsize(MODEL_SAVE_PATH) / 1024**2:.1f} MB\")\n",
    "print(f\"Location: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INSTALLATIE OP PI\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "Model staat op Google Drive. Op de Pi uitvoeren:\n",
    "\n",
    "1. Sync model naar Pi:\n",
    "   rclone copy gdrive:EMSN/nestbox_training/nestbox_species_model.pt /tmp/\n",
    "\n",
    "2. Kopieer naar NAS:\n",
    "   sudo cp /tmp/nestbox_species_model.pt /mnt/nas-birdnet-archive/nestbox/models/\n",
    "\n",
    "3. Test:\n",
    "   /home/ronny/emsn2/venv/bin/python3 \\\\\n",
    "     /home/ronny/emsn2/scripts/nestbox/nestbox_occupancy_detector.py \\\\\n",
    "     --all --verbose\n",
    "\n",
    "4. Check Grafana dashboard\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
